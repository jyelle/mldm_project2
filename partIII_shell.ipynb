{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part III: Ensembles and Final Result\n",
    "\n",
    "## AdaBoost\n",
    "\n",
    "Train an AdaBoost classifier using Decision Tree stubs as weak learners. Compare its performance to results obtained in Part II using 10 fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import proj2_lib.util as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_pipeline_file': 'feature_pipeline.pkl',\n",
       " 'labels_pipeline_file': 'labels_pipeline.pkl',\n",
       " 'objstore_path': 'objects',\n",
       " 'processed_data_path': 'processed_data',\n",
       " 'raw_data_csv': 'KaggleV2-May-2016.csv',\n",
       " 'raw_data_path': 'data',\n",
       " 'test_csv': 'test_set.csv',\n",
       " 'train_csv': 'train_set.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.file_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_config = utils.file_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ONLY NEED TO RUN THIS STEP ONCE (switch this to True to run it)\n",
    "RUN_MAKE_TRAIN_TEST_FILES = False\n",
    "if RUN_MAKE_TRAIN_TEST_FILES:\n",
    "    utils.make_train_test_sets(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import proj2_lib.preprocess as preprocess\n",
    "\n",
    "# ONLY NEED TO RUN THIS STEP ONCE\n",
    "RUN_FIT_PREPROCESSING = False\n",
    "if RUN_FIT_PREPROCESSING:\n",
    "    preprocess.fit_save_pipelines(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y = preprocess.load_train_data(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90526, 101)\n",
      "(90526,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "bdt.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy score using 10-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(bdt, train_X, train_y, \n",
    "                         scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79791440170735117"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy of AdaBoosted Decision Tree classifier\n",
    "\n",
    "import numpy as np\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the AdaBoosted Decision Tree classifier (~79.8%) > the accuracy of Linear SVM (~79.6%) > the accuracy of the Random Forest Classifier (~77.7%) > the accuracy of Decision Tree classifier (~73.8%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores = cross_val_score(bdt, train_X, train_y,\n",
    "                            scoring='roc_auc', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7257816926656615"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean AUC score of AdaBoosted Decision Tree classifier\n",
    "np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score of the AdaBoosted Decision Tree classifier (~72.6%) > the AUC score of the Random Forest classifier (~69.3%) > the AUC score of the Linear SVM (~66.7%) > the AUC score of the Decision Tree classifier (~58.3%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "Choose a set of 5 or so classifiers. Write a function that trains an ensemble using stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_stack_ensemble(X, y):\n",
    "    # create train/validation sets\n",
    "    # using StratifiedShuffleSplit\n",
    "    \n",
    "    # train classifiers in ensemble using train set\n",
    "    \n",
    "    # create new feature matrix for validation\n",
    "    # set by getting predictions from the ensemble\n",
    "    # classifiers\n",
    "    \n",
    "    # train logistic regression classifier on\n",
    "    # new feature matrix\n",
    "    \n",
    "    # return all trained classifiers\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 10-fold cross validation to measure performance of your stacked classifier. See Part II solution to see how to roll your own sklearn classifier along with http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result\n",
    "\n",
    "Choose a single model based on all previous project steps. Train this model on the complete training dataset and measure it's performance on the held out test set.\n",
    "\n",
    "Compare to the 10-fold CV estimate you got previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final result goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
